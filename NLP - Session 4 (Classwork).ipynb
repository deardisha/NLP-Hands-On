{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacaa4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c43767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I have a German Shepherd\", \"German Shepherd is from Germany\", \"Germans love gossiping\"]\n",
    "# 3 documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ba0918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f40c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d43684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have:5\n",
      "german:1\n",
      "shepherd:8\n",
      "is:6\n",
      "from:0\n",
      "germany:3\n",
      "germans:2\n",
      "love:7\n",
      "gossiping:4\n"
     ]
    }
   ],
   "source": [
    "for key in vocab.keys():\n",
    "    print(\"{}:{}\".format(key, vocab[key]))\n",
    "#numbers indicate index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b6de52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.transform([\"Germany has German Shepherd\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09e4a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([\"Germany has German Shepherd\"]).toarray(), vect.transform([\"Germany has Berlin as Capital\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a36fe23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity) #57% similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e2547",
   "metadata": {},
   "source": [
    "# Task: \n",
    "    1. Create a corpus of the articles of an author.\n",
    "    2. Vectorize them\n",
    "    3. Check cosine similarity between those articles and check their similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6a93351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vector = TfidfVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8907a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"If there is a phrase I would prefer to retire from online bios, personal or professional, it is, “I love travel.” Or some approximation of that sentiment. To clarify, I am not against travellers or those who proudly flaunt their passion for travel. On the contrary, editing a travel magazine has now made me oddly protective of travellers and their ilk. My submission is that “love to travel,” suggested so casually, just doesn’t feel adequate to the depth of emotion it sparks in true devotees.\", \n",
    "          \"The world’s greatest cities are brutal, unsentimental places, precisely the reason why so many of us fall so irrevocably under their spell. In its worst hour, this bond can curdle into bitter complaints of unrequited affection and everyday torment. “The subway doesn’t work, trash is overflowing and it’s too crowded; this is over.” Let me assure you that right now someone somewhere is uttering these words about your dream metropolis, New York, Rome, Rio De Janeiro. Like an unrepentant cad, the city laughs in their face, Go on… live without me.\", \n",
    "          \"As soon as a long, gleaming dark green train carriage, emblazoned with ‘Eastern & Oriental Express’ in engraved gold lettering slides into Hua Hin station, I feel a tinge of self-consciousness. Neither I nor my co-passengers from India are dressed for something this imperial. For the last hour, we have been milling about Hua Hin, Thailand’s oldest railway station—a quirky but fading royal artefact—in our baggy tees, jeans and dusty shoes, lugging backpacks and satchels. Once I hop aboard the train though, the air is less intimidating. While this is a majestic luxury locomotive boasting every accoutrement of refined sophistication, I see open, friendly faces in casual wear and summer hats.\",\n",
    "          \"After a tiring snorkelling session in the clear waters of Koh Phangan, instructors Captain Pumpui and Captain Poo are shepherding me and five others on a private speedboat to nearby Bottle Beach for a picnic lunch of sandwiches, macarons and fruit juices. I am about 10-12 kilometres from Belmond Napasai’s lush tropical resort in Koh Samui, my home for the last day-and-a-half, and the sun is blindingly bright overhead. This is ideal snorkelling weather; we have had a field day gasping at eels and corals underwater. But the heat has stymied chatter on our boat.\"\n",
    "         ]\n",
    "# 4 article paragraphs taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "155cf51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(binary=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82f8ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1a2667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if:100\n",
      "there:220\n",
      "is:109\n",
      "phrase:166\n",
      "would:256\n",
      "prefer:171\n",
      "to:227\n",
      "retire:182\n",
      "from:80\n",
      "online:153\n",
      "bios:24\n",
      "personal:164\n",
      "or:155\n",
      "professional:173\n",
      "it:110\n",
      "love:127\n",
      "travel:232\n",
      "some:199\n",
      "approximation:13\n",
      "of:149\n",
      "that:217\n",
      "sentiment:192\n",
      "clarify:43\n",
      "am:10\n",
      "not:146\n",
      "against:8\n",
      "travellers:233\n",
      "those:223\n",
      "who:248\n",
      "proudly:175\n",
      "flaunt:77\n",
      "their:219\n",
      "passion:163\n",
      "for:78\n",
      "on:151\n",
      "the:218\n",
      "contrary:48\n",
      "editing:62\n",
      "magazine:134\n",
      "has:90\n",
      "now:147\n",
      "made:133\n",
      "me:137\n",
      "oddly:148\n",
      "protective:174\n",
      "and:12\n",
      "ilk:101\n",
      "my:140\n",
      "submission:210\n",
      "suggested:212\n",
      "so:198\n",
      "casually:39\n",
      "just:115\n",
      "doesn:57\n",
      "feel:74\n",
      "adequate:5\n",
      "depth:55\n",
      "emotion:65\n",
      "sparks:205\n",
      "in:103\n",
      "true:235\n",
      "devotees:56\n",
      "world:254\n",
      "greatest:86\n",
      "cities:41\n",
      "are:14\n",
      "brutal:32\n",
      "unsentimental:240\n",
      "places:168\n",
      "precisely:170\n",
      "reason:179\n",
      "why:249\n",
      "many:136\n",
      "us:241\n",
      "fall:73\n",
      "irrevocably:108\n",
      "under:236\n",
      "spell:207\n",
      "its:111\n",
      "worst:255\n",
      "hour:97\n",
      "this:222\n",
      "bond:29\n",
      "can:35\n",
      "curdle:51\n",
      "into:107\n",
      "bitter:25\n",
      "complaints:46\n",
      "unrequited:239\n",
      "affection:6\n",
      "everyday:68\n",
      "torment:229\n",
      "subway:211\n",
      "work:253\n",
      "trash:231\n",
      "overflowing:160\n",
      "too:228\n",
      "crowded:50\n",
      "over:159\n",
      "let:121\n",
      "assure:17\n",
      "you:258\n",
      "right:183\n",
      "someone:200\n",
      "somewhere:202\n",
      "uttering:242\n",
      "these:221\n",
      "words:252\n",
      "about:3\n",
      "your:259\n",
      "dream:58\n",
      "metropolis:138\n",
      "new:144\n",
      "york:257\n",
      "rome:185\n",
      "rio:184\n",
      "de:54\n",
      "janeiro:112\n",
      "like:123\n",
      "an:11\n",
      "unrepentant:238\n",
      "cad:34\n",
      "city:42\n",
      "laughs:119\n",
      "face:70\n",
      "go:84\n",
      "live:124\n",
      "without:251\n",
      "as:16\n",
      "soon:203\n",
      "long:126\n",
      "gleaming:83\n",
      "dark:52\n",
      "green:87\n",
      "train:230\n",
      "carriage:37\n",
      "emblazoned:64\n",
      "with:250\n",
      "eastern:61\n",
      "oriental:156\n",
      "express:69\n",
      "engraved:66\n",
      "gold:85\n",
      "lettering:122\n",
      "slides:196\n",
      "hua:98\n",
      "hin:94\n",
      "station:208\n",
      "tinge:225\n",
      "self:191\n",
      "consciousness:47\n",
      "neither:143\n",
      "nor:145\n",
      "co:45\n",
      "passengers:162\n",
      "india:104\n",
      "dressed:59\n",
      "something:201\n",
      "imperial:102\n",
      "last:118\n",
      "we:244\n",
      "have:92\n",
      "been:22\n",
      "milling:139\n",
      "thailand:216\n",
      "oldest:150\n",
      "railway:178\n",
      "quirky:177\n",
      "but:33\n",
      "fading:72\n",
      "royal:186\n",
      "artefact:15\n",
      "our:158\n",
      "baggy:20\n",
      "tees:215\n",
      "jeans:113\n",
      "dusty:60\n",
      "shoes:195\n",
      "lugging:128\n",
      "backpacks:19\n",
      "satchels:189\n",
      "once:152\n",
      "hop:96\n",
      "aboard:2\n",
      "though:224\n",
      "air:9\n",
      "less:120\n",
      "intimidating:106\n",
      "while:247\n",
      "majestic:135\n",
      "luxury:131\n",
      "locomotive:125\n",
      "boasting:27\n",
      "every:67\n",
      "accoutrement:4\n",
      "refined:180\n",
      "sophistication:204\n",
      "see:190\n",
      "open:154\n",
      "friendly:79\n",
      "faces:71\n",
      "casual:38\n",
      "wear:245\n",
      "summer:213\n",
      "hats:91\n",
      "after:7\n",
      "tiring:226\n",
      "snorkelling:197\n",
      "session:193\n",
      "clear:44\n",
      "waters:243\n",
      "koh:117\n",
      "phangan:165\n",
      "instructors:105\n",
      "captain:36\n",
      "pumpui:176\n",
      "poo:169\n",
      "shepherding:194\n",
      "five:76\n",
      "others:157\n",
      "private:172\n",
      "speedboat:206\n",
      "nearby:142\n",
      "bottle:30\n",
      "beach:21\n",
      "picnic:167\n",
      "lunch:129\n",
      "sandwiches:188\n",
      "macarons:132\n",
      "fruit:81\n",
      "juices:114\n",
      "10:0\n",
      "12:1\n",
      "kilometres:116\n",
      "belmond:23\n",
      "napasai:141\n",
      "lush:130\n",
      "tropical:234\n",
      "resort:181\n",
      "samui:187\n",
      "home:95\n",
      "day:53\n",
      "half:89\n",
      "sun:214\n",
      "blindingly:26\n",
      "bright:31\n",
      "overhead:161\n",
      "ideal:99\n",
      "weather:246\n",
      "had:88\n",
      "field:75\n",
      "gasping:82\n",
      "at:18\n",
      "eels:63\n",
      "corals:49\n",
      "underwater:237\n",
      "heat:93\n",
      "stymied:209\n",
      "chatter:40\n",
      "boat:28\n"
     ]
    }
   ],
   "source": [
    "for key in vocab.keys():\n",
    "    print(\"{}:{}\".format(key, vocab[key]))\n",
    "#numbers indicate index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fda7d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([\"In this modern agnostic world, pop culture is the closest thing we have to a shared religion. Matinee idols, artists and rock stars are our gods and goddesses, feeding us an endless supply of enchanting lore and myths. For this movement to thrive though, it needs fans; followers who have gone beyond aloof observation. Pop culture requires that fans click below to subscribe, not let it just play in the background.\"]).toarray(), \n",
    "                               vect.transform([\"J R.R. Tolkien was right to portray the Ents, hulking pieces of tall barks with sad eyes and mossy facial hair who guarded forests, as perhaps the most stoic figures in his Lord of the Rings trilogy. Their whole manner spoke to an endurance that seemed constantly on the verge of dissipation. They had seen and tolerated far too much in a world at war with itself. Yet they remained calm, like a steady lighthouse in torrential downpour.\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0f884ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38559329]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46911e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38.55% Similarity between the articles written by Lakshmi Sankaran.\n",
    "# This prove that she indeed is a creative writer :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
